
## 说一说进程和线程的区别
- **基本概念区别**：进程是操作系统资源分配的基本单位，而线程是任务调度和执行的基本单位
- **开销区别**： 进程切换的开销要高于线程
- **所处环境区别**： 在操作系统中能同时运行多个进程（程序）；而在同一个进程（程序）中有多个线程同时执行（通过CPU调度，在每个时间片中只有一个线程执行）
- **内存分配方面**：系统在运行的时候会为每个进程分配不同的内存空间；而对线程而言，除了CPU外，系统不会为线程分配内存（线程所使用的资源来自其所属进程的资源），线程组之间只能共享资源。

<br></br>


## 实现多线程的方法
__1. 继承Thread类__
Thread类本身是实现Runnable接口的一个实例类，继承Thread类，重写run方法，并调用start方法启用一个新线程，并执行run()方法内部的逻辑，即可实现多线程能力。

```Java
public class MyThread extends Thread {
    public void run() {
        System.out.println("MyThread.run()");
    }
}
MyThread myThread1 = new MyThread();
myThread1.start();
```

__2. 实现Runnable接口__
定义一个实现了Runnable接口的类`MyRunnable`，并在类中实现run()接口方法，将`MuRunnable`的实例化对象作为参数传入一个`Thread`实例中，调用Thread实例的start()接口启动新线程。

``` Java
public class MyRunnable implements Runnable {
    public void run() {
        // 要执行的代码
    }
}
MyRunnable myRunnable = new MyRunnable();
Thread thread = new Thread(myRunnable);
thread.start();
```

__3. 使用Callable和Future接口__
- 定义一个实现了Callable接口的类`MuCallable`，并实现call()接口，该接口具备返回值并且可以抛出异常。
- 将该Callable任务提交到`ExecutorService`后，可以获得一个`Future`对象，这个对象代表着任务的生命周期，并且提供了一些方法来检查任务是否已经完成，取消任务，或者在任务完成后获取结果。在任务完成前，调用`get()`方法将会阻塞当前线程，直到结果可用。
  
```Java
public class NameCallable implements Callable<String> {
    @Override
    public String call() throws Exception {
        String name = "John Doe";
        return name;
    }
}

public class FutureExample {
    public static void main(String[] args) throws Exception {
        ExecutorService executor = Executors.newSingleThreadExecutor();
        Callable<String> callable = new NameCallable();
        Future<String> future = executor.submit(callable);
        String result = future.get();
        System.out.println(result);
        executor.shutdown();
    }
}
```

__4. 基于线程池的形式__
使用线程池管理线程的创建，任务分发，线程回收等生命周期的管理，可以极大减少因为线程创建销毁产生的资源消耗。
- **FixedThreadPool**：固定大小线程池。该线程池一旦被创建，其中包含的线程数就不会改变。如果所有线程都处于活动状态并且又有新的任务提交，那么这些任务就会在队列中等待，直到有线程可用为止。
- **CachedThreadPool**：缓存线程池。该线程池可以根据需要创建新线程，但在先前构造的线程可用时将重用它们；会清理缓存中长时间没有被调用的线程。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。
- **ScheduledThreadPool**：计划线程池。该线程池支持延迟执行或定时执行某个任务。例如，可以安排一个任务在5分钟后执行，或者每隔1秒执行一次。
- **SingleThreadExecutor**：单线程池。该线程池只包含一个线程，因此所有任务都是按顺序执行的。如果该线程因异常退出而结束，那么会创建一个新线程来替代它。

<br></br>

## submit()和execute()两种方法的区别
- **返回值类型不同**：execute()方法定义在Executor接口里，返回值类型为void；submit()对象的返回值是Future对象，定义在ExecutorService中
- **接受类型不同**：execute()方法仅接收Runnable类型的对象，而submit()可以接口Runnable和Callable类型的入参
- **异常抛出方式不同**：使用execute()提交任务时，如果出现异常会直接抛出；使用submit()提交任务时，如果出现异常不会直接抛出，而是等submit()返回的Future对象的get()方法被调用时，才会抛出异常

<br></br>

## 线程的生命周期
- **新建（NEW）**：线程刚被创建时处于的状态，已被分配了必须的内存资源，但是还没有启动。
- **就绪（RUNNABLE）**：当线程对象被调用start()方法时，JVM为其创建了方法调用栈和程序计数器，进入就绪状态，等待CPU调度执行。
- **运行（RUNNING）**：处于就绪状态的线程对象被调用run()方法，并获取CPU资源，可以运行run()方法内部的代码块，进入运行状态。
- **阻塞（BLOCKED）**：当线程因为某些原因让出CPU时间片，暂停运行，则进入的阻塞状态
  - 等待阻塞（Waiting）：当一个线程调用了`Object.wait()`、`Thread.join()`或`LockSupport.park()`方法时，它会进入等待阻塞状态。此时，它会释放占用的锁资源，并等待其他线程发出通知或中断。
  - 同步阻塞（Blocked）：当一个线程试图获取一个已经被其他线程占用的锁时，它会进入同步阻塞状态。此时，它会等待其他线程释放锁资源。
  - 其他阻塞（Sleeping）：当一个线程调用了`Thread.sleep()`方法时，它会进入其他阻塞状态。此时，它不会释放占用的锁资源，并等待指定时间后自动恢复。
- **死亡（TERMINATED）**：线程结束，释放内存资源，进入死亡状态
  - 等待线程的run方法执行完毕，正常结束线程
  - 使用interrupt方法终止线程
  - 使用stop方法强行终止线程

<br></br>

## notify()和notifyAll()有什么区别
- notify()方法随机唤醒对象的等待池中的一个线程，进入锁池；notifyAll()唤醒对象的等待池中的所有线程，进入锁池。
- 等待池是指调用了对象的wait()方法而释放锁的线程所在的队列，它们不会去竞争对象的锁；锁池是指等待获取对象锁的线程所在的队列，它们会去竞争对象的锁。
- 被唤醒的线程并不会立即执行，而是要等待获取对象锁后才能继续执行。如果使用notify()方法，只有一个线程会由等待池进入锁池，而其他线程仍然在等待被唤醒；如果使用notifyAll()方法，所有线程都会由等待池进入锁池，然后参与锁的竞争。
- 使用notify()方法可能会导致死锁，因为有可能唤醒的线程并不是能够继续执行的线程，而其他能够继续执行的线程却一直在等待；使用notifyAll()方法可以避免死锁，因为它会让所有线程都有机会获取对象锁。

<br>

## Thread.sleep()、Object.wait()、Condition.await()、LockSupport.park()的区别? 重点
### sleep()和wait() 有什么区别?
- **所属类不同：**`sleep()`是Thread类的本地方法，而`wait()`是Object对象的本地方法。
- **使用范围不同：**`sleep()`可以用在程序的任意位置，而`wait()`只能用在同步方法或者同步代码块中。
- **释放锁的状态不同：**`sleep()`方法不会释放当前线程持有的对象锁，而`wait()`方法会试放当前线程持有的对象锁，并进入等待池。
- **唤醒方式不同：**`sleep()`方法执行需要传入参数指定线程休眠时长，即必须指定休眠时长，超时时间过了后，则自动唤醒；`wait()`方法执行可以不传参，不传参代表永久休眠，但是需要其他线程执行notify()或notifyAll()方法才可以被唤醒。
- **使用场景不同：**`sleep()`方法用于当前线程休眠，而`wait()`方法用于线程之间的通信。

### Object.wait()和Condition.await()的区别
Condition.await()底层是调用LockSupport.park()来实现阻塞当前线程的；阻塞当前线程之前还干了两件事，一是把当前线程添加到条件队列中，二是“完全”释放锁，也就是让state状态变量变为0，然后才是调用LockSupport.park()阻塞当前线程。

### Thread.sleep()和LockSupport.park()的区别 
- 均堵塞线程，并且不会释放占用的锁资源
- sleep()可以自己唤醒，park()需要另外一个线程调用unpark()才能唤醒
- sleep()本身是native方法，而park()是调用unsafe的native方法

### Object.wait()和LockSupport.park()的区别
- wait()和notify()必须在同步代码块中配对使用，而park()和unpark()可以在任意位置使用
- wait()依赖于对象锁，而park()使用【许可证】机制，可以更加灵活的进行线程阻塞和线程唤醒


<br></br>

## 如何理解volatile关键字？
- volatile保证了可见性:即被volatile关键字修饰的变量，其发生变化时，会立刻被写回主存，其他所有线程都会知道该变量的变化；程序每次读取或修改该变量时，都会强制从主存中获取该变量的实际值，而不会优化内存读取，从线程本地内存中读取
- volatile禁止指令重排序，保证了部分程序的部分有序；可以保证程序执行到被修饰的变量的读写操作时，其之前的指令全部被执行，其变量的变化对后面的指令可见，其之后的指令全部没有执行；但是不能保证该指令前后的指令有序性。
  - 实例化一个对象分为三部分：分配内存空间，实例化对象，赋值给对应引用
  - 指令重排序会导致：分配内存空间，赋值给对应引用，实例化对象，导致将一个未初始化的对象引用暴露出来
- volatile关键字不能保证原子性。原子性是指一个操作不可拆分，全部执行成功或全部执行失败；因为volatile不会造成线程阻塞，所以一个被该关键字修饰的变量或者对象，可能会被多个线程访问或修改，所以无法保证原子性
### volatile的底层原理
内存屏障，防止指令重排序


<br></br>


## 如何理解Synchronized关键字？
- Synchronized关键字可以保证原子性，可见性和有序性
  - 原子性：当一个线程进入由`synchronized`修饰的方法或代码块时，该线程会获取到一个锁，只有当该线程释放锁后，其他线程才能进入该方法或代码块，保证了同一时间只有一个线程可以执行该方法或代码块，保证了原子性
  - 可见性：当一个线程进入一个`synchronized`方法或代码块时，它会清空线程本地内存中的共享变量的值，然后从主内存中重新读取最新的值。当该线程退出该方法或代码块时，它会把本地内存中的共享变量的值刷新到主内存中。这样就保证了一个线程对共享变量的修改能够被其他线程立即看到，从而保证了可见性。
  - 有序性：`synchronized`不允许指令重排序，但是可以保证同一时间只有一个线程进入被修饰的代码块或方法，所有操作都是按照代码顺序进行的，从而保证了有序性
- Synchronized关键字可以修饰实例方法，静态方法和代码块
  - 修饰实例方法：锁定当前对象实例，线程进入实例方法需要先获取当前对象实例的锁
  - 修饰静态方法：给当前类加锁，会影响到该类的所有实例对象，因为静态成员不属于任何一个实例对象；当多个线程同时访问该类的静态方法时，会出现阻塞现象；当线程A访问该类的静态方法，而线程B访问该类的某个实例对象的非静态方法，则不会发生互斥现象。**访问静态 synchronized 方法占用的锁是当前类的锁，而访问非静态synchronized 方法占用的锁是当前实例对象锁。**
  - 修饰代码块：锁定的是括号里配置的对象，如果多个线程同时访问同一个对象的synchronized代码块，那么这些线程将会被阻塞
### synchronized关键字的实现原理
使用monitorEnter和monitorExit两个指令实现：
- monitorEnter指令会使对象锁计数器加1，每个对象同一时间仅与一个锁相关，一个锁同一时间仅由一个线程获取。monitorEnter指令执行时会有三种情况：
  - 计数器为0，可以获取锁，获取锁后加1，其他线程无法再获取到当前对象的锁
  - 已经拿到锁，又重入了这个锁，锁计数器再次加一，此时计数器等于2
  - 当前锁已经被占据，需要等待
- monitorExit将monitor的计数器减1，如果减完以后，计数器不是0，则代表刚才是重入进来的，当前线程还继续持有这把锁的所有权，如果计数器变成0，则代表当前线程不再拥有该monitor的所有权，即释放锁。


<br></br>


## volatile和synchronized区别
- `作用范围不同`：volatile用于修饰变量，synchronized用于修饰一段代码或者一个方法
- `是否可以保证原子性`：volatile不能保证原子性，而synchronized可以同时保证原子性，可见性和有序性
- `性能区别`：多线程访问被volatile修饰的变量时不会被阻塞，而访问被synchronized修饰的代码块或方法时，可能会发生线程阻塞
- `实现有序性的方式不同`：volatile通过禁止指令重排序及在指令之间插入内存屏障指令来实现有序性；而synchronized不禁止重排序，而是单纯的避免了多线程仿真同一资源的场景。


<br></br>

## 为什么wait和notify方法要在同步块中调用？
- 在 Java 中，同步方法或同步块可以保证多个线程访问共享资源时的互斥性，即同一时间只有一个线程可以访问共享资源
- 调用目标对象的wait()之前，必须要保证当前线程拥有对象锁，才可以实现强制释放对象锁的能力
- 调用目标对象的notify()或notifyAll()之前，也必须保证当前线程可以获取到对象锁
- 上述两种情况都要求当前线程处于同步代码或同步块中，以保证共享资源的访问互斥性以及数据的一致性


<br></br>


## SynchronizedMap和ConcurrentHashMap有什么区别？
- 两种Map都是线程安全的
- SynchronizedMap类似于HashTable，在线程调用SynchronizedMap的成员方法时，会对整个Map进行同步，同一时刻只能有一个线程操作Map内的数据
- ConcurrentHashMap采用了分段锁，对Map中的所有`桶`加了锁，当某一线程访问其中一个桶时，该线程仅获取这一个桶的锁，其他线程仍然可以继续操作其他桶
- 两者比较下，安全性和性能都是ConcurrentHashMap更好


<br></br>


## Java中的锁
``` mermaid
flowchart LR
    JAVA主流锁 --> 乐观锁VS悲观锁 --- 是否锁住同步资源
    JAVA主流锁 --> 自旋锁VS非自旋锁 --- 同步资源加锁失败是否要阻塞线程
    JAVA主流锁 --> 公平锁VS非公平锁 --- 竞争同步资源的方式差别
    JAVA主流锁 --> 无锁VS偏向锁VS轻量级锁VS重量级锁 --- 线程竞争是否排队
    JAVA主流锁 --> 可重入锁VS不可重入锁 --- 一个线程内的多个流程是否可以获取同一锁
    JAVA主流锁 --> 独享锁VS共享锁 --- 多线程是否可以共享一把锁
```
<br></br>

- **乐观锁VS悲观锁**：是两种思想，体现了看待线程同步不同的角度
  - 乐观锁
    - 核心思想：认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。
    - 使用场景：读操作更多的场景，可以提升系统性能
  - 悲观锁：
    - 核心思想：对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。
    - 使用场景：写操作更多的场景，操作之前加锁保证数据写入正确。
- **自旋锁**：
  - 什么是自旋锁：自旋锁是一种基于忙等待的锁，当一个线程尝试获取锁时，如果该锁已被其他线程占用，则该线程将循环等待，不断地判断该锁是否能够被成功获取，直到获取到该锁为止。
  - 核心思想：在保证线程安全的前提下，尽量减少线程上下文切换的次数，从而提高系统性能。
  - 优势：
    - 自旋锁不会使线程进入阻塞状态，减少了线程上下文切换的次数，从而提高了系统性能。
    - 自旋锁适用于锁保护的临界区很小的情况。
  - 劣势：
    - 自旋锁需要占用CPU时间，如果自旋时间过长，则会浪费CPU资源。
    - 自旋锁不适用于锁保护的临界区很大或者锁竞争比较激烈的情况。、
  - 自适应自旋锁：自旋的时间不再固定了，而是由前一次在同一个锁上的自旋 时间及锁的拥有者的状态来决定的。
- **公平锁VS非公平锁**
  - 公平锁：多个线程按照申请锁的顺序来获取锁
    - 优势：等待锁的线程不会被饿死
    - 劣势：除队列第一个线程外，其他线程都会被阻塞，逐一唤醒会产生CPU消耗
  - 非公平锁：多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待，获取到则直接对同步资源进行加锁
    - 优势：减少唤起线程的开销，整体的吞吐效率高
    - 劣势：等待队列中的线程可能会出现饥饿现象 
- **可重入锁VS非可重入锁**
  - 可重入锁：又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。
    - 可以避免死锁
    - 可以减少上下文切换导致的CPU开销
  - 非可重入锁：不支持递归调用，如果一个线程在持有该锁的情况下，再次获取该锁，则会产生死锁。
- **共享锁VS独占锁**：共享锁和独占锁是指在多线程环境下，对于同一个资源，是否允许多个线程同时访问。如果允许多个线程同时访问，则该锁为共享锁；否则，该锁为独占锁。
- **偏向锁VS轻量级锁VS重量级锁**
  - 偏向锁：偏向锁是一种针对加锁操作的优化，它的核心思想是：如果一个线程获得了锁，那么锁就进入偏向模式，当这个线程再次请求锁时，无需再进行任何同步操作，即可直接获得锁。这样就省去了大量有关锁申请、调度、释放的操作，从而可以大幅度提高程序性能。
  - 轻量级锁：假设大部分同步代码一般都处于无锁竞争状态(即单线程执行环境)，在无锁竞争的情况下完全可以避免调用操作系统层面的重量级互斥锁，仅使用CAS一条指令实现加锁和释放锁。
  - 重量级锁：在竞争激烈的情况下，使用操作系统的互斥量来进行加锁和解锁操作。


<br></br>


## 锁优化有哪些方式？
1. 减少锁的持有时间：尽量缩小同步代码块的范围，只在必要的代码块加锁
2. 减小锁粒度：将一个大锁拆分为多个小锁，增加并行度，降低锁竞争的可能性
3. 锁粗化：将对同一个对象的多次加锁操作序列合并到同一个加锁同步范围内，以减少加锁和解锁的操作次数
4. 锁消除：编译器在编译阶段将某些不可能被共享的对象的锁删除，以避免没必要的加锁解锁操作
5. 轻量级锁
6. 偏向锁


<br></br>

## CAS的原理以及缺点
### 原理
CAS叫做CompareAndSwap，比较并交换，主要是通过处理器的指令来保证操作的原子性，它包含
三个操作数：
1. 变量内存地址，V表示
2. 旧的预期值，A表示
3. 准备设置的新值，B表示
当执行CAS指令时，只有当V等于A时，才会用B去更新V的值，否则就不会执行更新操作。
### 缺点
- ABA问题：ABA的问题指的是在CAS更新的过程中，当读取到的值是A，然后准备赋值的时候仍然是
A，但是实际上有可能A的值被改成了B，然后又被改回了A，这个CAS更新的漏洞就叫做ABA。
- 循环时间长开销大：自旋CAS的方式如果长时间不成功，会给CPU带来很大的开销。
- 只能保证一个共享变量的原子操作：只对一个共享变量操作可以保证原子性，但是多个则不行，多个可以通过AtomicReference来处理或者使用锁synchronized实现。

<br></br>

## 产生死锁的四个必要条件
- 互斥条件：一个资源每次只能被一个进程使用。
- 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
- 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。


<br></br>


## 线程池的拒绝策略
- AbortPolicy: 丢弃任务并抛出异常
- DiscardPolicy：丢弃任务并不抛出异常
- DiscardOldestPolicy：丢弃任务队列中的头节点，通常是存活时间最久的任务
- CallerRunsPolicy：将任务交还给调用线程（提交任务的线程）处理


<br></br>


## Java中的阻塞队列
### 原理
1. 当队列中没有数据的情况下，消费者端的所有线程都会被自动阻塞（挂起），直到有数据放
入队列。
2. 当队列中填满数据的情况下，生产者端的所有线程都会被自动阻塞（挂起），直到队列中有
空的位置，线程被自动唤醒。 

### 分类
| 队列类型 | 组成结构 | 特性 |
| :---: | :---: | :--- |
| ArrayBlockingQueue | 由数据结构构成的有界阻塞队列 | 按照FIFO的原则对队列中的数据进行排序<br>被阻塞的生成者或消费者按照被阻塞的顺序依次访问队列，以达到较为公平的模式 |
| LinkedBlockingQueue | 由链表组成的有界阻塞队列 | 遵循FIFO原则管理队列内数据<br>队首和队尾采用两个独立的锁进行管理，即生产者和消费者可以并行操作队列，提高队列的并发能力 |
| PriorityBlockingQueue | 基于堆实现的支持优先级排序的无界阻塞队列 | 根据自然顺序或自定义`compareTp()`方法对元素进行排序<br>不能保证同级数据的顺序 |
| DelayQueue | 支持延迟获取数据的无界阻塞队列 | 使用优先队列实现<br>队列中每一个元素必须实现`Delayed()`接口<br>创建元素时可以指定多久才能从队列中获取到该元素<br>可以用于实现缓存系统或任务调度系统 |
| SynchronousQueue | 不存储元素的阻塞队列 | 每一个put操作必须要等待一个take操作，否则不能继续添加元素<br>负责将生产者线程的元素直接传递给消费者线程 |
| LinkedTransferQueue | 由链表组成的无界阻塞队列 | 多了 tryTransfer 和 transfer 方法|
| LinkedBlockingDeque | 由链表组成的双向阻塞队列 | 支持从队列的两端插入或移出数据 |

 
<br>


## 什么是AQS，原理是什么
AQS（AbstractQueuedSynchronizer）是Java中用于构建锁和同步器的基础框架。它提供了一种用于实现阻塞算法的通用框架，并为自定义的同步器提供了基本的状态管理、线程调度和阻塞/唤醒机制。

### AQS的核心思想
如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制AQS是用CLH队列锁实现的，即将暂时获取不到锁的线程加入到队列中

### 实现依赖
AQS依赖Unsafe(提供CAS操作)和LockSupport(提供park/unpark操作)

### AQS的原理

- 状态管理：AQS内部维护了一个整型的状态变量，用于表示同步器的状态。同步器的状态可以被多个线程竞争和修改。

- 阻塞队列：AQS使用一个FIFO双向链表（CLH队列）作为阻塞队列，AQS是将每条请求共享资源的线程封装成一个CLH锁队列的一个结点(Node)来实现锁的分配。

- 线程挂起和唤醒：当线程无法获取同步器时，AQS会将线程阻塞，即将线程挂起并加入到阻塞队列中。当同步器的状态发生变化时（例如其他线程释放了锁），AQS会将阻塞队列中的线程唤醒，重新参与竞争。

- CAS操作：AQS使用CAS（Compare and Swap）操作来实现对状态的原子性修改。CAS操作可以保证只有一个线程能够成功修改状态，其他线程需要重试。

- 子类实现：AQS是一个抽象类，需要通过继承和实现其抽象方法来定义具体的同步器。子类可以通过继承AQS并重写相关方法，来实现自定义的同步逻辑。

AQS的设计使得它可以支持多种同步器的实现，如ReentrantLock、CountDownLatch、Semaphore等。

<br>


## Java线程池 ThreadPoolExecutor
### 原理
一个线程集合workerSet和一个阻塞队列workQueue。当用户向线程池提交一个任务(也就是线程)时，线程池会先将任务放入workQueue中。workerSet中的线程会不断的从workQueue中获取线程然后执行。当workQueue中没有任务的时候，worker就会阻塞，直到队列中有任务了就取出来继续执行。

### 一个任务的提交流程
1. 线程池首先当前运行的线程数量是否少于corePoolSize。如果是，则创建一个新的工作线程来执行任务。如果都在执行任务，则进入2
2. 判断BlockingQueue是否已经满了，倘若还没有满，则将线程放入BlockingQueue。否则进入3
3. 如果创建一个新的工作线程将使当前运行的线程数量超过maximumPoolSize，则交给RejectedExecutionHandler来处理任务。

### 核心参数
- corePoolSize：核心线程数
- workQueue：阻塞队列
- maximumPoolSize：当阻塞队列满了，且继续提交任务，则会新建线程执行任务，线程数需小于最大线程数；当阻塞队列是无界队列时，该参数无效
- keepAliveTime： 线程空闲时的存活时间，针对的是核心线程之外的救急线程
- threadFactory ：创建线程工厂
- hander：拒绝策略

### 线程池类型
- FixedThreadPool：线程池中的线程数量不会超过核心线程数，最大线程数和存活时间失效；实现无界阻塞队列，饱和策略失效
- SIngleThreadPool：仅有一个线程；使用无界阻塞队列，饱和策略失效
- CachedThreadPool：最大线程数为2^31 - 1，用SynchronousQueue作为阻塞队列；当线程的空闲时间超过keepAliveTime，会自动释放线程资源，当提交新任务时，如果没有空闲线程，则创建新线程执行任务

### 线程池任务提交流程
- submit任务，等待线程池execute执行
- FutureTask类的get方法时，会把主线程封装成WaitNode节点并保存在waiters链表中， 并阻塞等待运行结果；
- FutureTask任务执行完成后，通过UNSAFE设置waiters相应的waitNode为null，并通过LockSupport类unpark方法唤醒主线程；


<br>

## JUC工具类
### CountDown
#### 核心思想
同步一个或多个任务，强制他们等待其他任务完成后，主线程才会继续进行；是一次性的
#### 底层实现
将一个程序分为n个互相独立的可解决任务，并创建值为n的CountDownLatch。当每一个任务完成时，都会在这个锁存器上调用countDown，等待问题被解决的任务调用这个锁存器的await，将他们自己拦住，直至锁存器计数结束。

### CyclicBarrier
#### 核心思想
使用一个整型计数器来表示需要等待的线程数，当线程到达屏障时，会调用await()方法进行等待。当所有线程都到达屏障后，计数器会归零，所有等待的线程会被唤醒，然后继续执行后续操作。
### 底层实现 
使用了一个ReentrantLock来保证多个线程同时到达屏障时的互斥，使用Condition来实现线程的等待和唤醒。

### ThreadLocal
ThreadLocal在每个线程中对该变量会创建一个副本，即每个线程内部都会有一个该变量，且在线程内部任何地方都可以使用，线程之间互不影响，这样一来就不存在线程安全问题，也不会严重影响程序执行性能。


<br>


## HashTable为什么慢？
- 使用了同步锁：锁竞争和锁释放会导致性能下降
- 锁的粒度大，即对整个HashTable进行同步
- 扩容机制：扩容时需要重新计算hash值，并且需要重新分配内存空间，这会涉及到数据的迁移和重建，导致性能下降

## ConcurrentHashMap JDK 1.7
### 底层原理
保存了一个Segment数组，即将整个Hash表划分为多个分段；而每个Segment元素，它通过继承 ReentrantLock 来进行加锁，所以每次需要加锁的操作锁住的是一个 segment；默认是16个，即默认并发度为16，最大65536个；Seqgment内部由HashEntry数据构成，hashEntry最小容量是2.
### 扩容机制
当存储的键值对数量超过了ConcurrentHashMap的容量乘以加载因子时，ConcurrentHashMap会触发扩容操作。默认情况下，ConcurrentHashMap的加载因子为0.75
- 创建一个新的内部数据结构，其容量是原容量的两倍（Segment不扩容）。
- 将原来的键值对重新分布到新的HashEntry数组中，这个过程称为重新哈希（rehashing）。
- 该过程仅对当前这个Segment进行加锁

### put操作
存值先通过哈希高位映射出对应的分段，再通过低位映射出对应哈希表的索引，再通过链式处理哈希冲突，从而放值。
1. 通过hash函数计算出当前key的哈希值
2. 通过这个哈希值的高几位与掩码进行与运算，找到对应的Segment数组的下标
3. 再通过哈希值与HashEntry数组的长度-1进行与运算，获得HashEntry的下标
4. 判断当前HashEntry对应的链表，是否可获取ReetrantLock，获取则直接插入链表尾端，获取不到则线程自适应自旋尝试获取锁，直到超时被挂起或者拿到锁


## ConcurrentHashMap JDK 1.8
### 底层原理
table数组＋单向链表＋红黑树的结构；会存在一些队列长度过长的情况，如果还是采用单向列表方式，那么查询某个节点的时间复杂度为O(n)；因此，对于个数超过8(默认值)的列表，jdk1.8中采用了红黑树的结构，那么查询的时间复杂度可以降低到O(logN)
### 扩容机制

### put操作
- 如果没有初始化就先调用initTable（）方法来进行初始化过程
- 如果没有hash冲突就直接CAS插入
- 如果还在进行扩容操作就先进行扩容
- 如果存在hash冲突，就加锁来保证线程安全，这里有两种情况，一种是链表形式就直接遍历到尾端插入，一种是红黑树就按照红黑树结构插入，
- 最后一个如果该链表的数量大于阈值8，就要先转换成黑红树的结构，break再一次进入循环
- 如果添加成功就调用addCount（）方法统计size，并且检查是否需要扩容
